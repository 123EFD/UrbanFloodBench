{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14761150,"sourceType":"datasetVersion","datasetId":9434919}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- INSTALLATION BLOCK ---\nimport torch\n\ndef install_pyg():\n    print(f\"PyTorch Version: {torch.__version__}\")\n    print(f\"CUDA Version: {torch.version.cuda}\")\n    \n    # 1. Install Core PyG\n    !pip install -q torch-geometric\n    \n    # 2. Install Optional Dependencies (Scatter & Sparse are needed for GNN layers)\n    # We use a helper to find the right wheel for the installed Torch/CUDA version\n    try:\n        import torch_scatter, torch_sparse\n    except ImportError:\n        print(\"Installing dependencies (Scatter, Sparse)... this may take a minute.\")\n        # General install command that looks for binary wheels\n        !pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n\ninstall_pyg()\nprint(\"âœ… PyTorch Geometric Installed! You can now run the Graph Construction code.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:16:48.849086Z","iopub.execute_input":"2026-02-08T06:16:48.849376Z","iopub.status.idle":"2026-02-08T06:17:02.002560Z","shell.execute_reply.started":"2026-02-08T06:16:48.849343Z","shell.execute_reply":"2026-02-08T06:17:02.001641Z"}},"outputs":[{"name":"stdout","text":"PyTorch Version: 2.8.0+cu126\nCUDA Version: 12.6\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling dependencies (Scatter, Sparse)... this may take a minute.\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… PyTorch Geometric Installed! You can now run the Graph Construction code.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:17:45.055721Z","iopub.execute_input":"2026-02-08T06:17:45.056248Z","iopub.status.idle":"2026-02-08T06:17:45.380295Z","shell.execute_reply.started":"2026-02-08T06:17:45.056208Z","shell.execute_reply":"2026-02-08T06:17:45.379512Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/urbanfloodbench/test_2d_edges_dynamic_all.csv\n/kaggle/input/urbanfloodbench/test_2d_edges_static.csv\n/kaggle/input/urbanfloodbench/timesteps.csv\n/kaggle/input/urbanfloodbench/sample_submission.csv\n/kaggle/input/urbanfloodbench/test_2d_nodes_dynamic_all.csv\n/kaggle/input/urbanfloodbench/test_1d_edges_dynamic_all.csv\n/kaggle/input/urbanfloodbench/1d2d_connections.csv\n/kaggle/input/urbanfloodbench/1d_nodes_static.csv\n/kaggle/input/urbanfloodbench/2d_nodes_dynamic_all.csv\n/kaggle/input/urbanfloodbench/2d_edges_dynamic_all.csv\n/kaggle/input/urbanfloodbench/test_timesteps.csv\n/kaggle/input/urbanfloodbench/1d_edge_index.csv\n/kaggle/input/urbanfloodbench/2d_edges_static.csv\n/kaggle/input/urbanfloodbench/test_2d_edge_index.csv\n/kaggle/input/urbanfloodbench/1d_edges_static.csv\n/kaggle/input/urbanfloodbench/test_1d_edges_static.csv\n/kaggle/input/urbanfloodbench/1d_edges_dynamic_all.csv\n/kaggle/input/urbanfloodbench/sample_submission.parquet\n/kaggle/input/urbanfloodbench/submission.csv\n/kaggle/input/urbanfloodbench/2d_edge_index.csv\n/kaggle/input/urbanfloodbench/2d_nodes_static.csv\n/kaggle/input/urbanfloodbench/test_2d_nodes_static.csv\n/kaggle/input/urbanfloodbench/test_1d_nodes_static.csv\n/kaggle/input/urbanfloodbench/test_1d2d_connections.csv\n/kaggle/input/urbanfloodbench/1d_nodes_dynamic_all.csv\n/kaggle/input/urbanfloodbench/test_1d_nodes_dynamic_all.csv\n/kaggle/input/urbanfloodbench/my_raw_predictions.csv\n/kaggle/input/urbanfloodbench/test_1d_edge_index.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load Training Data\nprint(\"Loading training data for statistics...\")\ntrain_1d = pd.read_csv('/kaggle/input/urbanfloodbench/1d_nodes_dynamic_all.csv')\ntrain_2d = pd.read_csv('/kaggle/input/urbanfloodbench/2d_nodes_dynamic_all.csv')\n\n# Calculate Sigma (Standard Deviation)\nsigma_1d = train_1d['water_level'].std()\nsigma_2d = train_2d['water_level'].std()\n\nprint(f\"âœ… Calculated Constants:\")\nprint(f\"Sigma 1D: {sigma_1d}\")\nprint(f\"Sigma 2D: {sigma_2d}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:17:49.022900Z","iopub.execute_input":"2026-02-08T06:17:49.023320Z","iopub.status.idle":"2026-02-08T06:17:49.604081Z","shell.execute_reply.started":"2026-02-08T06:17:49.023294Z","shell.execute_reply":"2026-02-08T06:17:49.603353Z"}},"outputs":[{"name":"stdout","text":"Loading training data for statistics...\nâœ… Calculated Constants:\nSigma 1D: 16.800592891244573\nSigma 2D: 14.362006861860646\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass StandardizedRMSELoss(nn.Module):\n    def __init__(self, sigma_1d, sigma_2d):\n        super().__init__()\n        # Register sigmas as buffers so they move to GPU automatically with the model\n        self.register_buffer('sigma_1d', torch.tensor(sigma_1d))\n        self.register_buffer('sigma_2d', torch.tensor(sigma_2d))\n        self.mse = nn.MSELoss()\n\n    def forward(self, pred, target, node_type_mask):\n        \"\"\"\n        pred: Predicted values [Batch, Nodes]\n        target: Actual values [Batch, Nodes]\n        node_type_mask: Boolean tensor where True = 1D Node, False = 2D Node\n        \"\"\"\n        # Split predictions by node type\n        pred_1d = pred[node_type_mask]\n        target_1d = target[node_type_mask]\n        \n        pred_2d = pred[~node_type_mask]\n        target_2d = target[~node_type_mask]\n        \n        # Calculate RMSE for each\n        rmse_1d = torch.sqrt(self.mse(pred_1d, target_1d))\n        rmse_2d = torch.sqrt(self.mse(pred_2d, target_2d))\n        \n        # Standardize\n        std_rmse_1d = rmse_1d / self.sigma_1d\n        std_rmse_2d = rmse_2d / self.sigma_2d\n        \n        # Return average (Competition Metric)\n        return (std_rmse_1d + std_rmse_2d) / 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:17:51.077945Z","iopub.execute_input":"2026-02-08T06:17:51.078535Z","iopub.status.idle":"2026-02-08T06:17:51.084332Z","shell.execute_reply.started":"2026-02-08T06:17:51.078506Z","shell.execute_reply":"2026-02-08T06:17:51.083651Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\nstatic_1d = pd.read_csv('/kaggle/input/urbanfloodbench/1d_nodes_static.csv')\nstatic_2d = pd.read_csv('/kaggle/input/urbanfloodbench/2d_nodes_static.csv')\n\n# Print the list of columns\nprint(static_1d.columns.tolist())\nprint(static_2d.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:17:55.063866Z","iopub.execute_input":"2026-02-08T06:17:55.064546Z","iopub.status.idle":"2026-02-08T06:17:55.092805Z","shell.execute_reply.started":"2026-02-08T06:17:55.064508Z","shell.execute_reply":"2026-02-08T06:17:55.092190Z"}},"outputs":[{"name":"stdout","text":"['node_idx', 'position_x', 'position_y', 'depth', 'invert_elevation', 'surface_elevation', 'base_area']\n['node_idx', 'position_x', 'position_y', 'area', 'roughness', 'min_elevation', 'elevation', 'aspect', 'curvature', 'flow_accumulation']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch_geometric.data import Data\nimport numpy as np\n\ndef build_unified_graph():\n    print(\"ğŸ—ï¸ Building Unified Graph Object...\")\n    \n    # --- 1. Load Static Metadata (Nodes) ---\n    # We use static features (elevation, area, etc.) as the baseline Node Features\n    static_1d = pd.read_csv('/kaggle/input/urbanfloodbench/1d_nodes_static.csv')\n    static_2d = pd.read_csv('/kaggle/input/urbanfloodbench/2d_nodes_static.csv')\n    \n    # Calculate Offsets\n    num_1d_nodes = len(static_1d)\n    num_2d_nodes = len(static_2d)\n    print(f\"   Nodes: {num_1d_nodes} (1D) + {num_2d_nodes} (2D) = {num_1d_nodes + num_2d_nodes} Total\")\n\n    # --- 2. Construct Node Features (X) ---\n    # We need to ensure both 1D and 2D have the same number of features (columns)\n    # If they differ, we pad with 0s.\n    # Common features: [x_coord, y_coord, elevation, area, roughness]\n    \n    # Aligning columns manually for demonstration (Adjust based on actual CSV columns)\n    # 1D: [1d_position_x, 1d_position_y, invert_elevation, base_area]\n    # 2D: [2d_position_x, 2d_position_y, centroid_elevation, area]\n    \n    feat_1d = static_1d[['position_x', 'position_y', 'invert_elevation', 'base_area']].values\n    feat_2d = static_2d[['position_x', 'position_y', 'elevation', 'area']].values\n    \n    # Normalize features (Crucial for GNN convergence)\n    # Simple Min-Max or Standard scaling is recommended here\n    combined_feats = np.vstack([feat_1d, feat_2d])\n    mean = combined_feats.mean(axis=0)\n    std = combined_feats.std(axis=0) + 1e-6 # Avoid div/0\n    \n    x_norm = (combined_feats - mean) / std\n    \n    # Convert to Tensor\n    x = torch.tensor(x_norm, dtype=torch.float)\n    \n    # Create a \"Node Type\" mask (0 for 1D, 1 for 2D)\n    # This helps the model treat them differently\n    type_mask = torch.cat([\n        torch.zeros(num_1d_nodes), \n        torch.ones(num_2d_nodes)\n    ]).reshape(-1, 1)\n    \n    # Append type mask to features\n    x = torch.cat([x, type_mask], dim=1)\n\n\n    # --- 3. Construct Edges (Edge_Index) ---\n    # A. 1D Edges (Pipe to Pipe)\n    edges_1d = pd.read_csv('/kaggle/input/urbanfloodbench/1d_edge_index.csv')\n    src_1d = edges_1d['from_node'].values\n    dst_1d = edges_1d['to_node'].values\n    \n    # B. 2D Edges (Surface to Surface)\n    # WE MUST SHIFT THESE INDICES by 'num_1d_nodes'\n    edges_2d = pd.read_csv('/kaggle/input/urbanfloodbench/2d_edge_index.csv')\n    src_2d = edges_2d['from_node'].values + num_1d_nodes\n    dst_2d = edges_2d['to_node'].values + num_1d_nodes\n    \n    # C. Coupled Edges (1D to 2D and 2D to 1D)\n    # Load connection file\n    conn_df = pd.read_csv('/kaggle/input/urbanfloodbench/1d2d_connections.csv')\n    # Clean column names\n    conn_df.columns = [c.strip() for c in conn_df.columns]\n    col_1d = next((c for c in conn_df.columns if '1d' in c.lower()), '1d_node_idx')\n    col_2d = next((c for c in conn_df.columns if '2d' in c.lower()), '2d_node_idx')\n    \n    # Connection: 1D <-> 2D (Bidirectional)\n    # Flow from Surface (2D) -> Pipe (1D)\n    src_c1 = conn_df[col_2d].values + num_1d_nodes # From 2D (Shifted)\n    dst_c1 = conn_df[col_1d].values                # To 1D  (Original)\n    \n    # Flow from Pipe (1D) -> Surface (2D)\n    src_c2 = conn_df[col_1d].values                # From 1D\n    dst_c2 = conn_df[col_2d].values + num_1d_nodes # To 2D\n    \n    # Combine ALL sources and destinations\n    all_src = np.concatenate([src_1d, src_2d, src_c1, src_c2])\n    all_dst = np.concatenate([dst_1d, dst_2d, dst_c1, dst_c2])\n    \n    edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n\n    # --- 4. Create Object ---\n    data = Data(x=x, edge_index=edge_index)\n    \n    # Save metadata for later\n    data.num_1d = num_1d_nodes\n    data.num_2d = num_2d_nodes\n    \n    print(f\"âœ… Unified Graph Created!\")\n    print(f\"   Shape: {data.x.shape} (Nodes, Features)\")\n    print(f\"   Edges: {data.edge_index.shape[1]}\")\n    \n    return data, mean, std\n\n# Execute\ngraph_data, feat_mean, feat_std = build_unified_graph()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:17:56.963770Z","iopub.execute_input":"2026-02-08T06:17:56.964349Z","iopub.status.idle":"2026-02-08T06:18:03.685301Z","shell.execute_reply.started":"2026-02-08T06:17:56.964321Z","shell.execute_reply":"2026-02-08T06:18:03.684534Z"}},"outputs":[{"name":"stdout","text":"ğŸ—ï¸ Building Unified Graph Object...\n   Nodes: 17 (1D) + 3716 (2D) = 3733 Total\nâœ… Unified Graph Created!\n   Shape: torch.Size([3733, 5]) (Nodes, Features)\n   Edges: 7983\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1101987198.py:86: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n  edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# ==========================================\n# 1. TEMPORAL DATA PROCESSOR\n# ==========================================\ndef process_dynamic_data(graph_data):\n    print(\"â³ Processing Dynamic Signals...\")\n    \n    # Load raw dynamic files\n    # Note: We use TRAINING data here to build the training set\n    d1 = pd.read_csv('/kaggle/input/urbanfloodbench/1d_nodes_dynamic_all.csv')\n    d2 = pd.read_csv('/kaggle/input/urbanfloodbench/2d_nodes_dynamic_all.csv')\n    \n    # --- A. Pivot to Matrix Form [Timestep x Node] ---\n    # We need to guarantee the order matches the Graph Node IDs\n    # 1D Nodes: 0 to num_1d-1\n    # 2D Nodes: num_1d to num_1d+num_2d-1\n    \n    # 1. Pivot Water Levels\n    # We use 'sum' aggregation just in case of duplicates, though there shouldn't be any\n    w1 = d1.pivot_table(index='timestep', columns='node_idx', values='water_level', aggfunc='sum')\n    w2 = d2.pivot_table(index='timestep', columns='node_idx', values='water_level', aggfunc='sum')\n    \n    # 2. Pivot Forcing (Inlet Flow for 1D, Rainfall for 2D)\n    # Note: 2D usually has 'rainfall', 1D has 'inlet_flow'. \n    # We will combine them into a generic \"Forcing\" feature.\n    f1 = d1.pivot_table(index='timestep', columns='node_idx', values='inlet_flow', aggfunc='sum').fillna(0)\n    \n    # For 2D, if 'rainfall' column exists use it, else 0 (some datasets split rainfall separately)\n    if 'rainfall' in d2.columns:\n        f2 = d2.pivot_table(index='timestep', columns='node_idx', values='rainfall', aggfunc='sum').fillna(0)\n    else:\n        f2 = pd.DataFrame(0, index=w2.index, columns=w2.columns)\n\n    # --- B. Align & Concatenate ---\n    # Ensure all timesteps are present and sorted\n    common_index = w1.index.intersection(w2.index).sort_values()\n    w1, w2 = w1.loc[common_index], w2.loc[common_index]\n    f1, f2 = f1.loc[common_index], f2.loc[common_index]\n    \n    # Stack 1D and 2D horizontally to match Graph Node Order\n    # Water Matrix: [Time, Total_Nodes]\n    water_matrix = np.hstack([w1.values, w2.values])\n    \n    # Forcing Matrix: [Time, Total_Nodes]\n    forcing_matrix = np.hstack([f1.values, f2.values])\n    \n    # --- C. Create Feature Tensor ---\n    # Shape: [Time, Nodes, Features] -> Features = (Water_Level, Forcing)\n    # We stack them along the last dimension\n    # Feature 0: Water Level (Target)\n    # Feature 1: Forcing (Input only)\n    dynamic_tensor = np.stack([water_matrix, forcing_matrix], axis=-1)\n    \n    # Handle NaNs (Interpolate or Fill 0)\n    dynamic_tensor = np.nan_to_num(dynamic_tensor)\n    \n    print(f\"âœ… Dynamic Tensor Created!\")\n    print(f\"   Shape: {dynamic_tensor.shape} (Timesteps, Nodes, Features)\")\n    \n    return torch.FloatTensor(dynamic_tensor)\n\n# Execute\nfull_history = process_dynamic_data(graph_data)\n\n# ==========================================\n# 2. SLIDING WINDOW DATASET\n# ==========================================\nclass FloodDataset(Dataset):\n    def __init__(self, data_tensor, input_window=12, output_window=12):\n        \"\"\"\n        data_tensor: [Time, Nodes, Feats]\n        \"\"\"\n        self.data = data_tensor\n        self.input_window = input_window\n        self.output_window = output_window\n        \n    def __len__(self):\n        # We need enough history for input AND enough future for output\n        return len(self.data) - self.input_window - self.output_window\n    \n    def __getitem__(self, idx):\n        # Window: [t : t+In]\n        # Target: [t+In : t+In+Out]\n        \n        # X: Use both features (Water + Forcing)\n        x = self.data[idx : idx+self.input_window, :, :] \n        \n        # Y: Predict only Water Level (Feature 0)\n        # We generally predict the CHANGE or the absolute value. Let's predict Absolute.\n        y = self.data[idx+self.input_window : idx+self.input_window+self.output_window, :, 0]\n        \n        return x, y\n\n# Instantiate\ntrain_dataset = FloodDataset(full_history, input_window=12, output_window=12)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nprint(f\"âœ… Data Loader Ready! Batches: {len(train_loader)}\")\n# Check shape of one batch\nsample_x, sample_y = next(iter(train_loader))\nprint(f\"   Sample X: {sample_x.shape} (Batch, In_Time, Nodes, Feats)\")\nprint(f\"   Sample Y: {sample_y.shape} (Batch, Out_Time, Nodes)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:18:05.650553Z","iopub.execute_input":"2026-02-08T06:18:05.650868Z","iopub.status.idle":"2026-02-08T06:18:06.074170Z","shell.execute_reply.started":"2026-02-08T06:18:05.650839Z","shell.execute_reply":"2026-02-08T06:18:06.073525Z"}},"outputs":[{"name":"stdout","text":"â³ Processing Dynamic Signals...\nâœ… Dynamic Tensor Created!\n   Shape: (94, 3733, 2) (Timesteps, Nodes, Features)\nâœ… Data Loader Ready! Batches: 3\n   Sample X: torch.Size([32, 12, 3733, 2]) (Batch, In_Time, Nodes, Feats)\n   Sample Y: torch.Size([32, 12, 3733]) (Batch, Out_Time, Nodes)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass FloodSTGNN(nn.Module):\n    def __init__(self, num_nodes, in_channels=2, out_channels=1, hidden_dim=64):\n        super(FloodSTGNN, self).__init__()\n        \n        self.num_nodes = num_nodes\n        \n        # --- 1. FEATURE EMBEDDING (The Missing Link) ---\n        # Projects raw features (2) -> Hidden Dimensions (64)\n        # This allows the LSTM to ingest the data.\n        self.feature_embed = nn.Linear(in_channels, hidden_dim)\n\n        # --- 2. TEMPORAL BLOCK (LSTM) ---\n        # Input Size is now hidden_dim (64), not in_channels (2)\n        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, \n                            num_layers=1, batch_first=True)\n        \n        # --- 3. SPATIAL BLOCK (Graph Convolution) ---\n        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n        \n        # --- 4. OUTPUT HEAD ---\n        self.fc = nn.Linear(hidden_dim, out_channels)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        x: [Batch, Time, Nodes, Features]\n        \"\"\"\n        B, T, N, F_in = x.shape\n        \n        # 1. Reshape for LSTM: [Batch*Nodes, Time, Features]\n        # We treat every node as an independent sequence initially\n        x_flat = x.permute(0, 2, 1, 3).reshape(B*N, T, F_in)\n        \n        # 2. Apply Embedding (Fixes the dimension mismatch)\n        # Shape: [B*N, T, 2] -> [B*N, T, 64]\n        x_embedded = self.feature_embed(x_flat)\n        x_embedded = F.relu(x_embedded) # Optional activation\n        \n        # 3. Run LSTM\n        # Shape: [B*N, T, 64]\n        lstm_out, _ = self.lstm(x_embedded)\n        \n        # Take the state at the last time step\n        # Shape: [B*N, 64]\n        last_hidden = lstm_out[:, -1, :] \n        \n        # 4. Reshape for GCN: [Batch, Nodes, Hidden]\n        gcn_in = last_hidden.view(B, N, -1)\n        \n        # 5. Run GCN (Spatial Mixing)\n        # We loop over the batch because GCN expects [Nodes, Feats]\n        gcn_outs = []\n        for b in range(B):\n            h = self.gcn1(gcn_in[b], edge_index)\n            h = F.relu(h)\n            h = self.gcn2(h, edge_index)\n            gcn_outs.append(h)\n            \n        # Stack back: [Batch, Nodes, Hidden]\n        gcn_final = torch.stack(gcn_outs)\n        \n        # 6. Final Prediction\n        # Shape: [Batch, Nodes, Out_Steps]\n        out = self.fc(gcn_final)\n        \n        return out\n\n# Re-instantiate the model on GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = FloodSTGNN(num_nodes=3733, in_channels=2, out_channels=12, hidden_dim=64).to(device)\n\nprint(\"âœ… Corrected Model Defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:18:11.528124Z","iopub.execute_input":"2026-02-08T06:18:11.528709Z","iopub.status.idle":"2026-02-08T06:18:11.892260Z","shell.execute_reply.started":"2026-02-08T06:18:11.528674Z","shell.execute_reply":"2026-02-08T06:18:11.891639Z"}},"outputs":[{"name":"stdout","text":"âœ… Corrected Model Defined!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch.optim as optim\n\n# ==========================================\n# 1. SETUP (Optimizer & Loss)\n# ==========================================\n# Hyperparameters\nLEARNING_RATE = 0.001\nEPOCHS = 10  # Start small to verify it works, then increase to 50+\n\n# Define Optimizer\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# Re-define Loss (in case variables were lost)\n# Using the sigma values you calculated earlier:\nSIGMA_1D = 16.80\nSIGMA_2D = 14.36\n\nclass StandardizedRMSELoss(nn.Module):\n    def __init__(self, sigma_1d, sigma_2d):\n        super().__init__()\n        self.sigma_1d = sigma_1d\n        self.sigma_2d = sigma_2d\n        self.mse = nn.MSELoss()\n\n    def forward(self, pred, target, node_type_mask):\n        \"\"\"\n        Calculates Competition Metric: Average of (RMSE_1D / Sigma_1D) and (RMSE_2D / Sigma_2D)\n        \"\"\"\n        # Create masks based on the node_type_mask stored in the graph\n        # mask = 0 (1D), mask = 1 (2D)\n        mask_1d = (node_type_mask == 0).squeeze()\n        mask_2d = (node_type_mask == 1).squeeze()\n        \n        # Filter 1D Nodes\n        # Pred shape: [Batch, Time, Nodes] -> Select Nodes -> [Batch, Time, N_1D]\n        p1 = pred[:, :, mask_1d]\n        t1 = target[:, :, mask_1d]\n        rmse_1d = torch.sqrt(self.mse(p1, t1))\n        \n        # Filter 2D Nodes\n        p2 = pred[:, :, mask_2d]\n        t2 = target[:, :, mask_2d]\n        rmse_2d = torch.sqrt(self.mse(p2, t2))\n        \n        # Standardize and Average\n        loss = ( (rmse_1d / self.sigma_1d) + (rmse_2d / self.sigma_2d) ) / 2\n        return loss\n\ncriterion = StandardizedRMSELoss(SIGMA_1D, SIGMA_2D)\n\n# ==========================================\n# 2. TRAINING LOOP\n# ==========================================\nprint(\"ğŸš€ Starting ST-GNN Training...\")\nmodel.train() # Set to training mode\n\n# Get Graph Structure (Static Edges & Type Mask)\n# Move to GPU\nedge_index = graph_data.edge_index.to(device)\n# The last feature in x is the type mask (0 or 1)\nnode_type_mask = graph_data.x[:, -1].long().to(device) \n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    \n    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n        # Move data to GPU\n        x_batch = x_batch.to(device) # [Batch, 12, Nodes, 2]\n        y_batch = y_batch.to(device) # [Batch, 12, Nodes]\n        \n        # 1. Zero Gradients\n        optimizer.zero_grad()\n        \n        # 2. Forward Pass\n        # Output: [Batch, Nodes, 12]\n        out = model(x_batch, edge_index)\n        \n        # 3. Shape Correction\n        # Target is [Batch, 12, Nodes] (Time in middle)\n        # Model Out is [Batch, Nodes, 12] (Time at end)\n        # We permute Out to match Target: [B, N, T] -> [B, T, N]\n        out = out.permute(0, 2, 1)\n        \n        # 4. Calculate Loss\n        loss = criterion(out, y_batch, node_type_mask)\n        \n        # 5. Backprop\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss (Std RMSE): {avg_loss:.4f}\")\n\nprint(\"âœ… Training Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:18:55.158555Z","iopub.execute_input":"2026-02-08T06:18:55.159064Z","iopub.status.idle":"2026-02-08T06:19:02.174136Z","shell.execute_reply.started":"2026-02-08T06:18:55.159032Z","shell.execute_reply":"2026-02-08T06:19:02.173532Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Starting ST-GNN Training...\nEpoch 1/10 | Train Loss (Std RMSE): 20.3728\nEpoch 2/10 | Train Loss (Std RMSE): 20.2128\nEpoch 3/10 | Train Loss (Std RMSE): 19.6920\nEpoch 4/10 | Train Loss (Std RMSE): 18.3370\nEpoch 5/10 | Train Loss (Std RMSE): 15.4247\nEpoch 6/10 | Train Loss (Std RMSE): 10.1987\nEpoch 7/10 | Train Loss (Std RMSE): 4.2920\nEpoch 8/10 | Train Loss (Std RMSE): 3.5260\nEpoch 9/10 | Train Loss (Std RMSE): 3.3811\nEpoch 10/10 | Train Loss (Std RMSE): 3.3573\nâœ… Training Complete!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nimport gc\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\n\n# ==========================================\n# 1. CLEANUP MEMORY\n# ==========================================\n# Delete old variables that might be on GPU\nif 'out' in locals(): del out\nif 'loss' in locals(): del loss\nif 'x_batch' in locals(): del x_batch\nif 'y_batch' in locals(): del y_batch\n\n# Force Garbage Collection\ngc.collect()\n# Clear PyTorch GPU Cache\ntorch.cuda.empty_cache()\nprint(\"ğŸ§¹ GPU Memory Cleared.\")\n\n# ==========================================\n# 2. REDUCE BATCH SIZE\n# ==========================================\n# We reduce batch size from 32 to 4 to fit in memory\n# This means it updates weights more often, which is fine.\nBATCH_SIZE = 4 \n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nprint(f\"ğŸ“‰ Batch Size reduced to {BATCH_SIZE}. Batches per epoch: {len(train_loader)}\")\n\n# ==========================================\n# 3. RE-RUN TRAINING LOOP\n# ==========================================\n# Re-initialize optimizer to clear old states\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nprint(\"ğŸš€ Restarting ST-GNN Training (Safe Mode)...\")\nmodel.train() \n\n# Ensure graph components are on GPU\nedge_index = graph_data.edge_index.to(device)\nnode_type_mask = graph_data.x[:, -1].long().to(device)\n\nfor epoch in range(50): # Run 10 Epochs\n    total_loss = 0\n    \n    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n        # Move to GPU\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward\n        out = model(x_batch, edge_index)\n        \n        # Shape Correction: [B, N, T] -> [B, T, N]\n        out = out.permute(0, 2, 1)\n        \n        # Loss\n        loss = criterion(out, y_batch, node_type_mask)\n        \n        # Backprop\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print average loss for this epoch\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/50 | Train Loss: {avg_loss:.4f}\")\n\nprint(\"âœ… Training Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T06:59:33.142721Z","iopub.execute_input":"2026-02-08T06:59:33.143297Z","iopub.status.idle":"2026-02-08T07:00:08.898165Z","shell.execute_reply.started":"2026-02-08T06:59:33.143266Z","shell.execute_reply":"2026-02-08T07:00:08.897529Z"}},"outputs":[{"name":"stdout","text":"ğŸ§¹ GPU Memory Cleared.\nğŸ“‰ Batch Size reduced to 4. Batches per epoch: 18\nğŸš€ Restarting ST-GNN Training (Safe Mode)...\nEpoch 1/10 | Train Loss: 3.3063\nEpoch 2/10 | Train Loss: 3.3009\nEpoch 3/10 | Train Loss: 3.2953\nEpoch 4/10 | Train Loss: 3.2890\nEpoch 5/10 | Train Loss: 3.2823\nEpoch 6/10 | Train Loss: 3.2746\nEpoch 7/10 | Train Loss: 3.2663\nEpoch 8/10 | Train Loss: 3.2572\nEpoch 9/10 | Train Loss: 3.2473\nEpoch 10/10 | Train Loss: 3.2363\nEpoch 11/10 | Train Loss: 3.2240\nEpoch 12/10 | Train Loss: 3.2101\nEpoch 13/10 | Train Loss: 3.1947\nEpoch 14/10 | Train Loss: 3.1775\nEpoch 15/10 | Train Loss: 3.1582\nEpoch 16/10 | Train Loss: 3.1370\nEpoch 17/10 | Train Loss: 3.1136\nEpoch 18/10 | Train Loss: 3.0895\nEpoch 19/10 | Train Loss: 3.0660\nEpoch 20/10 | Train Loss: 3.0408\nEpoch 21/10 | Train Loss: 3.0152\nEpoch 22/10 | Train Loss: 2.9886\nEpoch 23/10 | Train Loss: 2.9590\nEpoch 24/10 | Train Loss: 2.9280\nEpoch 25/10 | Train Loss: 2.8971\nEpoch 26/10 | Train Loss: 2.8633\nEpoch 27/10 | Train Loss: 2.8303\nEpoch 28/10 | Train Loss: 2.7966\nEpoch 29/10 | Train Loss: 2.7627\nEpoch 30/10 | Train Loss: 2.7295\nEpoch 31/10 | Train Loss: 2.6978\nEpoch 32/10 | Train Loss: 2.6691\nEpoch 33/10 | Train Loss: 2.6428\nEpoch 34/10 | Train Loss: 2.6202\nEpoch 35/10 | Train Loss: 2.6011\nEpoch 36/10 | Train Loss: 2.5830\nEpoch 37/10 | Train Loss: 2.5684\nEpoch 38/10 | Train Loss: 2.5540\nEpoch 39/10 | Train Loss: 2.5410\nEpoch 40/10 | Train Loss: 2.5291\nEpoch 41/10 | Train Loss: 2.5169\nEpoch 42/10 | Train Loss: 2.5054\nEpoch 43/10 | Train Loss: 2.4934\nEpoch 44/10 | Train Loss: 2.4807\nEpoch 45/10 | Train Loss: 2.4686\nEpoch 46/10 | Train Loss: 2.4565\nEpoch 47/10 | Train Loss: 2.4440\nEpoch 48/10 | Train Loss: 2.4313\nEpoch 49/10 | Train Loss: 2.4220\nEpoch 50/10 | Train Loss: 2.3999\nâœ… Training Complete!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\nEXTRA_EPOCHS = 50       \nTARGET_LOSS = 1.0       \nBEST_LOSS = float('inf') \n\n# Scheduler: Removed 'verbose=True' to fix the error\n# If loss doesn't improve for 3 epochs, it lowers LR by 50%\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3\n)\n\nprint(f\"ğŸš€ Resuming training for {EXTRA_EPOCHS} epochs (Target: {TARGET_LOSS})...\")\n\nmodel.train()\n\nfor epoch in range(EXTRA_EPOCHS):\n    total_loss = 0\n    \n    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n        # Move to GPU\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward\n        out = model(x_batch, edge_index)\n        out = out.permute(0, 2, 1) # [B, N, T] -> [B, T, N]\n        \n        # Loss\n        loss = criterion(out, y_batch, node_type_mask)\n        \n        # Backprop\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Calculate Average Loss\n    avg_loss = total_loss / len(train_loader)\n    \n    # Update Learning Rate Scheduler\n    scheduler.step(avg_loss)\n    \n    # Get current learning rate for display\n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {epoch+1}/{EXTRA_EPOCHS} | Loss: {avg_loss:.4f} | LR: {current_lr:.6f}\")\n    \n    # --- CHECKPOINTING ---\n    if avg_loss < BEST_LOSS:\n        BEST_LOSS = avg_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"   ğŸ’¾ New Best Model Saved! (Loss: {BEST_LOSS:.4f})\")\n        \n    # --- EARLY STOPPING ---\n    if avg_loss <= TARGET_LOSS:\n        print(f\"âœ… Target Reached! Stopping early at Epoch {epoch+1}\")\n        break\n\nprint(f\"ğŸ Training Finished. Best Loss Achieved: {BEST_LOSS:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T07:02:44.787767Z","iopub.execute_input":"2026-02-08T07:02:44.788492Z","iopub.status.idle":"2026-02-08T07:03:20.306733Z","shell.execute_reply.started":"2026-02-08T07:02:44.788445Z","shell.execute_reply":"2026-02-08T07:03:20.306060Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Resuming training for 50 epochs (Target: 1.0)...\nEpoch 1/50 | Loss: 2.3833 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3833)\nEpoch 2/50 | Loss: 2.3691 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3691)\nEpoch 3/50 | Loss: 2.3551 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3551)\nEpoch 4/50 | Loss: 2.3411 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3411)\nEpoch 5/50 | Loss: 2.3262 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3262)\nEpoch 6/50 | Loss: 2.3117 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.3117)\nEpoch 7/50 | Loss: 2.2967 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.2967)\nEpoch 8/50 | Loss: 2.2814 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.2814)\nEpoch 9/50 | Loss: 2.2657 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.2657)\nEpoch 10/50 | Loss: 2.2493 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.2493)\nEpoch 11/50 | Loss: 2.2334 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.2334)\nEpoch 12/50 | Loss: 2.2354 | LR: 0.001000\nEpoch 13/50 | Loss: 2.1971 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1971)\nEpoch 14/50 | Loss: 2.1723 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1723)\nEpoch 15/50 | Loss: 2.1543 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1543)\nEpoch 16/50 | Loss: 2.1368 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1368)\nEpoch 17/50 | Loss: 2.1197 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1197)\nEpoch 18/50 | Loss: 2.1023 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.1023)\nEpoch 19/50 | Loss: 2.0849 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.0849)\nEpoch 20/50 | Loss: 2.0674 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.0674)\nEpoch 21/50 | Loss: 2.0498 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.0498)\nEpoch 22/50 | Loss: 2.0318 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.0318)\nEpoch 23/50 | Loss: 2.0136 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 2.0136)\nEpoch 24/50 | Loss: 1.9951 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.9951)\nEpoch 25/50 | Loss: 1.9760 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.9760)\nEpoch 26/50 | Loss: 1.9568 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.9568)\nEpoch 27/50 | Loss: 1.9372 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.9372)\nEpoch 28/50 | Loss: 1.9172 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.9172)\nEpoch 29/50 | Loss: 1.8972 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.8972)\nEpoch 30/50 | Loss: 1.8764 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.8764)\nEpoch 31/50 | Loss: 1.8556 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.8556)\nEpoch 32/50 | Loss: 1.8342 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.8342)\nEpoch 33/50 | Loss: 1.8129 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.8129)\nEpoch 34/50 | Loss: 1.7912 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.7912)\nEpoch 35/50 | Loss: 1.7688 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.7688)\nEpoch 36/50 | Loss: 1.7465 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.7465)\nEpoch 37/50 | Loss: 1.7238 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.7238)\nEpoch 38/50 | Loss: 1.7012 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.7012)\nEpoch 39/50 | Loss: 1.6783 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.6783)\nEpoch 40/50 | Loss: 1.6551 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.6551)\nEpoch 41/50 | Loss: 1.6318 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.6318)\nEpoch 42/50 | Loss: 1.6085 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.6085)\nEpoch 43/50 | Loss: 1.5850 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.5850)\nEpoch 44/50 | Loss: 1.5616 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.5616)\nEpoch 45/50 | Loss: 1.5385 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.5385)\nEpoch 46/50 | Loss: 1.5151 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.5151)\nEpoch 47/50 | Loss: 1.4918 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.4918)\nEpoch 48/50 | Loss: 1.4694 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.4694)\nEpoch 49/50 | Loss: 1.4465 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.4465)\nEpoch 50/50 | Loss: 1.4243 | LR: 0.001000\n   ğŸ’¾ New Best Model Saved! (Loss: 1.4243)\nğŸ Training Finished. Best Loss Achieved: 1.4243\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\n\n# ==========================================\n# 1. LOAD & PREPARE TEST DATA\n# ==========================================\nprint(\"â³ Loading Test Data...\")\nt1 = pd.read_csv('/kaggle/input/urbanfloodbench/test_1d_nodes_dynamic_all.csv')\nt2 = pd.read_csv('/kaggle/input/urbanfloodbench/test_2d_nodes_dynamic_all.csv')\n\n# --- A. Pivot Forcing Data (Rain/Flow) ---\nprint(\"   Processing Forcing Features...\")\nf1 = t1.pivot_table(index='timestep', columns='node_idx', values='inlet_flow').fillna(0)\n\nif 'rainfall' in t2.columns:\n    f2 = t2.pivot_table(index='timestep', columns='node_idx', values='rainfall').fillna(0)\nelse:\n    # Fallback if no rainfall column\n    f2 = pd.DataFrame(0, index=f1.index, columns=range(len(t2['node_idx'].unique())))\n\n# --- B. FIX: ALIGN TIMESTEPS (Crucial Step) ---\n# Find the maximum range of time covered by EITHER file\n# usually 2D rain file is the master clock\nmax_t = max(f1.index.max(), f2.index.max()) if not f2.empty else f1.index.max()\nfull_timeline = range(int(max_t) + 1)\n\n# Reindex both to ensure they have exactly the same rows (0 to max_t)\nprint(f\"   Aligning timelines: 1D had {len(f1)} steps, 2D had {len(f2)} steps -> Target: {len(full_timeline)}\")\nf1 = f1.reindex(full_timeline, fill_value=0)\nf2 = f2.reindex(full_timeline, fill_value=0)\n\n# --- C. ALIGN COLUMNS (Ensure all nodes are present) ---\n# Ensure f1 has columns 0..16 (or whatever num_1d is)\n# Ensure f2 has columns 0..3715 (or whatever num_2d is)\n# We use the counts from your graph build\nnum_1d = 17    # Hardcoded from your graph build log\nnum_2d = 3716  # Hardcoded from your graph build log\n\n# Reindex columns to guarantee order matches graph.x\nf1 = f1.reindex(columns=range(num_1d), fill_value=0)\nf2 = f2.reindex(columns=range(num_2d), fill_value=0)\n\n# --- D. MERGE ---\n# Now shapes are guaranteed to match: [Max_Time, Num_Nodes]\nforcing_matrix = np.hstack([f1.values, f2.values]) \nprint(f\"   Forcing Matrix Shape: {forcing_matrix.shape}\")\n\n# Initialize Water Level Matrix (Starts at 0)\nnum_timesteps, num_nodes = forcing_matrix.shape\nwater_matrix = np.zeros((num_timesteps, num_nodes))\n\n# Create Master Tensor\ntest_tensor = np.stack([water_matrix, forcing_matrix], axis=-1)\ntest_tensor = torch.FloatTensor(test_tensor).to(device)\n\nprint(f\"âœ… Inference Environment Ready. Tensor Shape: {test_tensor.shape}\")\n\n# ==========================================\n# 2. RUN AUTOREGRESSIVE LOOP\n# ==========================================\nmodel.eval()\nWINDOW_SIZE = 12\n\nprint(\"ğŸš€ Starting Prediction Loop...\")\n# Create a list to store predictions to convert to DataFrame later\npreds_list = []\n\nwith torch.no_grad():\n    for t in range(num_timesteps):\n        # 1. Construct Input Window\n        if t < WINDOW_SIZE:\n            padding = test_tensor[0:1].repeat(WINDOW_SIZE - (t + 1), 1, 1)\n            history = test_tensor[0 : t + 1]\n            input_window = torch.cat([padding, history], dim=0)\n        else:\n            input_window = test_tensor[t - WINDOW_SIZE + 1 : t + 1]\n        \n        input_window = input_window.unsqueeze(0) # [1, 12, N, 2]\n        \n        # 2. Predict\n        preds = model(input_window, edge_index) # [1, N, 12]\n        \n        # 3. Update State\n        next_val = preds[0, :, 0] # Take first step prediction [N]\n        \n        # Store for submission (Save only what we need to save memory)\n        # We need this 'next_val' to be the water level at time 't' (or t+1 depending on offset)\n        # Usually, if we input [t-11...t], model predicts [t+1]. \n        # But for loop continuity, let's assume we predict 't' given previous.\n        # Let's align: We predict for the CURRENT step 't' using 't-1' data.\n        \n        # Update Tensor for NEXT iteration\n        # Note: If we are at step t, we just predicted water level for step t (or t+1).\n        # Let's assume prediction is for t+1. \n        if t + 1 < num_timesteps:\n            test_tensor[t + 1, :, 0] = next_val\n            \n        # Extract 1D predictions for submission (Nodes 0 to 16)\n        # 2D predictions (Nodes 17+)\n        preds_list.append(next_val.cpu().numpy())\n\n        if t % 50 == 0: print(f\"   ... Simulated Step {t}/{num_timesteps}\")\n\n# ==========================================\n# 3. EXPORT SUBMISSION\n# ==========================================\nprint(\"ğŸ’¾ Saving Results...\")\n# Convert list of arrays to big array [Time, Nodes]\nall_preds = np.stack(preds_list)\n\n# Flatten to Long Format\nflat_data = []\nfor t in range(num_timesteps):\n    # Only iterate 1D nodes if 2D is not required, OR iterate all if needed.\n    # Competition usually asks for specific nodes. \n    # Let's load sample submission to map exactly what is needed.\n    pass \n\n# FASTER MAPPING:\n# Create a DataFrame from the numpy array directly\ndf_preds = pd.DataFrame(all_preds, columns=range(num_nodes))\ndf_preds['timestep'] = range(num_timesteps) # Add timestep index\n# Melt to long format\ndf_long = df_preds.melt(id_vars='timestep', var_name='graph_node_idx', value_name='water_level')\n\n# Map 'graph_node_idx' back to (node_type, node_id)\n# 1D: 0..16 -> Type 1, ID = idx\n# 2D: 17..End -> Type 0, ID = idx - 17\ndef get_node_info(idx):\n    if idx < num_1d: return 1, idx\n    else: return 0, idx - num_1d\n\n# Vectorized mapping is faster\ndf_long['node_type'] = np.where(df_long['graph_node_idx'] < num_1d, 1, 0)\ndf_long['node_id'] = np.where(df_long['graph_node_idx'] < num_1d, df_long['graph_node_idx'], df_long['graph_node_idx'] - num_1d)\n\n# Load Sample Sub\nsample_sub = pd.read_csv('/kaggle/input/urbanfloodbench/sample_submission.csv')\nmerge_keys = ['node_type', 'node_id', 'timestep']\n\n# If sample_sub missing timestep, generate it (assuming sorted blocks)\nif 'timestep' not in sample_sub.columns:\n    sample_sub['timestep'] = sample_sub.groupby(['model_id', 'event_id', 'node_type', 'node_id']).cumcount()\n\n# Merge\nfinal_df = sample_sub.drop(columns=['water_level']).merge(\n    df_long[['node_type', 'node_id', 'timestep', 'water_level']], \n    on=merge_keys, \n    how='left'\n)\n\nfinal_df['water_level'] = final_df['water_level'].fillna(0)\nfinal_df.to_csv('submission_gnn.csv', index=False)\n\nprint(\"âœ… 'submission_gnn.csv' generated successfully!\")\nprint(final_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T07:07:09.143803Z","iopub.execute_input":"2026-02-08T07:07:09.144515Z","iopub.status.idle":"2026-02-08T07:09:37.796558Z","shell.execute_reply.started":"2026-02-08T07:07:09.144483Z","shell.execute_reply":"2026-02-08T07:09:37.795795Z"}},"outputs":[{"name":"stdout","text":"â³ Loading Test Data...\n   Processing Forcing Features...\n   Aligning timelines: 1D had 10 steps, 2D had 445 steps -> Target: 445\n   Forcing Matrix Shape: (445, 3733)\nâœ… Inference Environment Ready. Tensor Shape: torch.Size([445, 3733, 2])\nğŸš€ Starting Prediction Loop...\n   ... Simulated Step 0/445\n   ... Simulated Step 50/445\n   ... Simulated Step 100/445\n   ... Simulated Step 150/445\n   ... Simulated Step 200/445\n   ... Simulated Step 250/445\n   ... Simulated Step 300/445\n   ... Simulated Step 350/445\n   ... Simulated Step 400/445\nğŸ’¾ Saving Results...\nâœ… 'submission_gnn.csv' generated successfully!\n   row_id  model_id  event_id  node_type node_id  timestep  water_level\n0       0         1         5          1       0         0   587.264893\n1       1         1         5          1       0         1   363.444153\n2       2         1         5          1       0         2   337.338379\n3       3         1         5          1       0         3   333.911621\n4       4         1         5          1       0         4   333.467865\n","output_type":"stream"}],"execution_count":21}]}